# Validation Study Protocol for SynthScope
## Title: Evaluating the Performance of SynthScope: A Large Language Model-based Automatic Systematic Review Tool

### Background and Rationale
Systematic reviews are essential for synthesizing evidence and informing decision-making in various research fields. However, conducting a systematic review is a labor-intensive and time-consuming process. The advent of large language models (LLMs) provides an opportunity to automate parts of the systematic review process, potentially saving time and reducing errors. SynthScope is a novel automatic systematic review tool that utilizes advanced LLMs to summarize and synthesize scientific literature. This study aims to evaluate the performance of SynthScope in conducting systematic reviews compared to traditional human-completed reviews.

### Objectives
- Assess the accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) of SynthScope in identifying relevant articles for systematic reviews.
- Compare the performance of SynthScope to that of human reviewers in conducting systematic reviews.
- Determine the utility and usability of SynthScope in real-world scenarios by engaging independent researchers.
Methods
### Study Design
This validation study will employ a quasi-experimental design with two parallel arms:

- SynthScope-generated systematic reviews
- Human-completed systematic reviews
Sample Selection
 - Identify 10 highly-cited systematic reviews across diverse research fields and domains, ensuring a representative sample.
- For each selected review, retrieve the original search results from the respective databases, including all articles screened for eligibility.

**Intervention**
- For each selected systematic review, SynthScope will be used to:
    - Screen titles and abstracts for eligibility.
    - Review full-text articles for inclusion and exclusion criteria.
    - Summarize and synthesize the included articles.
    Comparator
 - For each selected systematic review, a team of human reviewers will independently:
    - Screen titles and abstracts for eligibility.
    - Review full-text articles for inclusion and exclusion criteria.
    - Summarize and synthesize the included articles.
**Data Extraction and Analysis**
- For each systematic review, extract the final list of included articles generated by both SynthScope and human reviewers.
- Assess the performance of SynthScope by calculating the following metrics:
Sensitivity: The proportion of relevant articles identified by SynthScope compared to human reviewers.
Specificity: The proportion of non-relevant articles correctly excluded by SynthScope compared to human reviewers.
PPV: The proportion of relevant articles identified by SynthScope among all articles deemed relevant by the tool.
NPV: The proportion of non-relevant articles correctly excluded by SynthScope among all articles deemed non-relevant by the tool.
Conduct a sub-group analysis to assess the performance of SynthScope across different research fields and domains.
Analyze the qualitative feedback from independent researchers to evaluate the usability and utility of SynthScope in real-world scenarios.
Further Validation
Engage five independent researchers from diverse research fields to test SynthScope on their own systematic reviews.
Collect performance metrics and qualitative feedback from these researchers to validate SynthScope's accuracy and utility.
Timeline
Sample selection and preparation: 1 month
Intervention and data extraction: 2 months
Data analysis and manuscript preparation: 2 months
Further validation with independent researchers: 3 months
Ethical Considerations
This study does not involve human subjects, human material, or human data, and therefore does not require ethical approval. All data used in this study will be extracted from publicly available sources. Any potential conflicts of interest will be disclosed by the authors.

Dissemination
The findings of this validation study will be submitted for publication in a peer-reviewed journal in the field of systematic reviews or AI in research. Furthermore, the results will be presented at relevant conferences and workshops to reach a wider audience of researchers and practitioners.

In addition to formal publication and presentation, the study findings will be disseminated through various channels, such as blog posts, social media, webinars, and press releases. The aim is to raise awareness of SynthScope's capabilities and potential impact on the systematic review process.

Limitations and Future Directions
Potential limitations of this validation study may include:

Limited generalizability due to the sample of systematic reviews selected for evaluation. Future studies could include a larger and more diverse sample of systematic reviews to better assess SynthScope's performance across different research fields and domains.
Inherent differences between human reviewers and AI-based tools in terms of the review process and decision-making. Future research could explore methods to harmonize the approaches of human reviewers and AI-based tools for more accurate comparisons.
The rapidly evolving nature of LLMs, which may lead to significant improvements in SynthScope's performance over time. Future validation studies should be conducted as LLMs continue to advance, to ensure that the tool remains relevant and effective.
As SynthScope evolves and its performance improves, future studies could also explore the integration of SynthScope with other systematic review tools and platforms to enhance the efficiency of the entire review process. Additionally, research could examine the role of SynthScope in meta-analyses and other forms of evidence synthesis, to further demonstrate its utility and potential impact in research.